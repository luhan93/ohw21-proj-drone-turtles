# Turtle Detection at OceanHackWeek 2021
Thanks to technical advancements in drones and autonomous underwater vehicles, we are now able to capture large amounts of data from marine environments. However, the major limiting factors is the human-power it takes to label datasets of such size. With deep learning, the task of classification can be automated with high accuracy. Here, we present results using YOLOv5 to classify and localize turtles from drone images. The network is trained with images from Nick Mortimer at CSIRO and we manually labelled 450 images using makesense.ai.

Object detection is a task in computer vision that involves identifying the presence, location, and type of one or more objects in a given photograph. It is a challenging problem that involves building upon methods for object recognition (e.g. where are they), object localization (e.g. what are their extent), and object classification (e.g. what are they).In recent years, deep learning techniques are achieving state-of-the-art results for object detection, such as on standard benchmark datasets and in computer vision competitions. YOLO originally started in 2016 up to v5 at the moment. The approach involves a single convolutional neural network (CNN) that splits the input into a grid of cells and each cell directly predicts a bounding box and object classification. The result is a large number of candidate bounding boxes that are consolidated into a final prediction by a post-processing step, using non-max suppression. In this project, we implemented YOLOv5 in Pytorch, trained the model with 450 drone taken turtle images, and successfully detected the turtle in a drone taken video.

We created a Dash App with the results and deployed it on Heruko. Please see the app at https://detectdronetutle.herokuapp.com.
